{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# import librart\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "import feature_select\n",
    "import feture_process\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.sparse import load_npz\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./project_data_files/book_rating_train.csv\")\n",
    "test_df = pd.read_csv(\"./project_data_files/book_rating_test.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot code Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process Prublisher and Language\n",
    "train_df[\"Language\"], test_df[\"Language\"] = feture_process.docclass_preprocess(train_df[\"Language\"],test_df[\"Language\"],10)\n",
    "train_df[\"Publisher\"], test_df[\"Publisher\"] = feture_process.docclass_preprocess(train_df[\"Publisher\"],test_df[\"Publisher\"],200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use oneHotCode for Publisher (sklearn)\n",
    "publisher_train_hot = feture_process.process_OneHotEncoder(train_df,\"Publisher\")\n",
    "publisher_test_hot = feture_process.process_OneHotEncoder(test_df,\"Publisher\")\n",
    "train_df = pd.concat([train_df, publisher_train_hot], axis=1)\n",
    "test_df = pd.concat([test_df, publisher_test_hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use oneHotCode for Language (sklearn)\n",
    "language_train_hot = feture_process.process_OneHotEncoder(train_df,\"Language\")\n",
    "language_test_hot = feture_process.process_OneHotEncoder(test_df,\"Language\")\n",
    "train_df = pd.concat([train_df, language_train_hot], axis=1)\n",
    "test_df = pd.concat([test_df, language_test_hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use oneHotCode for label (sklearn)\n",
    "label_train_hot = feture_process.process_OneHotEncoder(train_df,\"rating_label\")\n",
    "train_df = pd.concat([train_df, label_train_hot], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countvectorizer processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_name_countvectorizer\n",
    "train_name_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_name_countvectorizer.pkl\", \"rb\"))\n",
    "train_name_dic = train_name_countvectorizer.vocabulary_\n",
    "\n",
    "# train_authors_countvectorizer\n",
    "train_authors_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_authors_countvectorizer.pkl\", \"rb\"))\n",
    "train_authors_dic = train_authors_countvectorizer.vocabulary_\n",
    "\n",
    "# train_desc_countvectorizer\n",
    "train_desc_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_desc_countvectorizer.pkl\", \"rb\"))\n",
    "train_desc__dic = train_desc_countvectorizer.vocabulary_\n",
    "\n",
    "# process vector features\n",
    "train_name_features = train_name_countvectorizer.transform(train_df['Name'])\n",
    "train_authors_features = train_authors_countvectorizer.transform(train_df['Authors'])\n",
    "train_desc_features = train_desc_countvectorizer.transform(train_df['Description'])\n",
    "other_features_df = train_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language','rating_label_3.0', 'rating_label_4.0', 'rating_label_5.0', 'rating_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new sparse features\n",
    "sparse_features = hstack([train_name_features, train_authors_features, train_desc_features])\n",
    "# new train features\n",
    "dense_features = csr_matrix(other_features_df.values)\n",
    "train_features = hstack([sparse_features, dense_features])\n",
    "\n",
    "\n",
    "# process test features\n",
    "test_name_features = scipy.sparse.load_npz('./project_data_files/book_text_features_countvec/test_name_vec.npz')\n",
    "test_authors_features = scipy.sparse.load_npz('./project_data_files/book_text_features_countvec/test_authors_vec.npz')\n",
    "test_desc_features = scipy.sparse.load_npz('./project_data_files/book_text_features_countvec/test_desc_vec.npz')\n",
    "test_other_features_df = test_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language'])\n",
    "\n",
    "test_sparse_features = hstack([test_name_features, test_authors_features, test_desc_features])\n",
    "new_dense_features = csr_matrix(test_other_features_df.values)\n",
    "test_features = hstack([test_sparse_features, new_dense_features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc2vec processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use doc2vec\n",
    "# use doc2vec\n",
    "# use doc2vec\n",
    "# use doc2vec\n",
    "\n",
    "# process vector features\n",
    "train_name_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/train_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "train_authors_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/train_authors_doc2vec20.csv\", index_col = False, delimiter = ',', header=None)\n",
    "train_desc_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/train_desc_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "other_features_df = train_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language', 'rating_label', 'rating_label_3.0', 'rating_label_4.0', 'rating_label_5.0'])\n",
    "train_features = pd.concat([train_name_features, train_authors_features, train_desc_features, other_features_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use doc2vec\n",
    "# use doc2vec\n",
    "# use doc2vec\n",
    "# use doc2vec\n",
    "\n",
    "# process test features\n",
    "test_name_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/test_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_authors_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/test_authors_doc2vec20.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_desc_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/test_desc_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_other_features_df = test_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language'])\n",
    "test_features = pd.concat([test_name_features, test_authors_features, test_desc_features, test_other_features_df], axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features,selected_features_test = train_features,test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features,selected_features_test = feature_select.MI(train_df,train_features,test_features,12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features,selected_features_test = feature_select.chi_square(train_df,train_features,test_features,12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = load_npz(\"selected_features_label_one_hot_12000.npz\")\n",
    "selected_features_test = load_npz(\"selected_features_test_label_one_hot_12000.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1, l2\n",
    "\n",
    "\n",
    "input_dim = selected_features.shape[1] \n",
    "num_classes = label_train_hot.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(input_dim,), kernel_regularizer=l2(0.0001)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(selected_features, label_train_hot, test_size=0.3, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.toarray()\n",
    "X_val = X_val.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "unique_classes = np.unique(y_train)\n",
    "sample_weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 1.1608 - accuracy: 0.1887 - val_loss: 1.2803 - val_accuracy: 0.2727\n",
      "Epoch 2/50\n",
      "505/505 [==============================] - 6s 11ms/step - loss: 0.8854 - accuracy: 0.2605 - val_loss: 1.7428 - val_accuracy: 0.1828\n",
      "Epoch 3/50\n",
      "505/505 [==============================] - 6s 11ms/step - loss: 0.7368 - accuracy: 0.3344 - val_loss: 1.5214 - val_accuracy: 0.2743\n",
      "Epoch 4/50\n",
      "505/505 [==============================] - 5s 11ms/step - loss: 0.5935 - accuracy: 0.4431 - val_loss: 1.0175 - val_accuracy: 0.5244\n",
      "Epoch 5/50\n",
      "505/505 [==============================] - 5s 11ms/step - loss: 0.6080 - accuracy: 0.4806 - val_loss: 1.4510 - val_accuracy: 0.3154\n",
      "Epoch 6/50\n",
      "505/505 [==============================] - 5s 11ms/step - loss: 0.5093 - accuracy: 0.5258 - val_loss: 1.1732 - val_accuracy: 0.4188\n",
      "Epoch 7/50\n",
      "505/505 [==============================] - 5s 11ms/step - loss: 0.4697 - accuracy: 0.5773 - val_loss: 1.5309 - val_accuracy: 0.3094\n",
      "Epoch 8/50\n",
      "505/505 [==============================] - 5s 11ms/step - loss: 0.4496 - accuracy: 0.6166 - val_loss: 1.1692 - val_accuracy: 0.4470\n",
      "Epoch 9/50\n",
      "505/505 [==============================] - 5s 11ms/step - loss: 0.4278 - accuracy: 0.6360 - val_loss: 1.3977 - val_accuracy: 0.3972\n",
      "Epoch 10/50\n",
      "505/505 [==============================] - 6s 11ms/step - loss: 0.3697 - accuracy: 0.6856 - val_loss: 1.1962 - val_accuracy: 0.5255\n",
      "Epoch 11/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.4224 - accuracy: 0.6729 - val_loss: 1.3848 - val_accuracy: 0.3600\n",
      "Epoch 12/50\n",
      "505/505 [==============================] - 7s 13ms/step - loss: 0.4808 - accuracy: 0.6424 - val_loss: 1.1733 - val_accuracy: 0.5144\n",
      "Epoch 13/50\n",
      "505/505 [==============================] - 6s 11ms/step - loss: 0.3848 - accuracy: 0.6805 - val_loss: 1.0569 - val_accuracy: 0.5921\n",
      "Epoch 14/50\n",
      "505/505 [==============================] - 5s 11ms/step - loss: 0.4100 - accuracy: 0.6791 - val_loss: 1.2173 - val_accuracy: 0.5298\n",
      "Epoch 15/50\n",
      "505/505 [==============================] - 5s 11ms/step - loss: 0.3540 - accuracy: 0.7144 - val_loss: 1.3984 - val_accuracy: 0.5098\n",
      "Epoch 16/50\n",
      "505/505 [==============================] - 5s 10ms/step - loss: 0.2927 - accuracy: 0.7644 - val_loss: 1.1239 - val_accuracy: 0.6803\n",
      "Epoch 17/50\n",
      "505/505 [==============================] - 5s 10ms/step - loss: 0.3844 - accuracy: 0.6866 - val_loss: 0.9389 - val_accuracy: 0.5827\n",
      "Epoch 18/50\n",
      "505/505 [==============================] - 6s 11ms/step - loss: 0.2916 - accuracy: 0.7708 - val_loss: 1.2311 - val_accuracy: 0.5473\n",
      "Epoch 19/50\n",
      "505/505 [==============================] - 6s 11ms/step - loss: 0.3099 - accuracy: 0.7708 - val_loss: 1.7186 - val_accuracy: 0.4421\n",
      "Epoch 20/50\n",
      "505/505 [==============================] - 6s 11ms/step - loss: 0.3003 - accuracy: 0.7701 - val_loss: 1.2025 - val_accuracy: 0.6460\n",
      "Epoch 21/50\n",
      "505/505 [==============================] - 6s 11ms/step - loss: 0.2562 - accuracy: 0.8066 - val_loss: 1.3126 - val_accuracy: 0.6154\n",
      "Epoch 22/50\n",
      "505/505 [==============================] - 7s 14ms/step - loss: 0.5072 - accuracy: 0.6528 - val_loss: 1.3964 - val_accuracy: 0.5592\n",
      "Epoch 23/50\n",
      "505/505 [==============================] - 7s 14ms/step - loss: 0.3383 - accuracy: 0.7401 - val_loss: 1.0478 - val_accuracy: 0.6341\n",
      "Epoch 24/50\n",
      "505/505 [==============================] - 8s 16ms/step - loss: 0.2611 - accuracy: 0.8079 - val_loss: 1.2931 - val_accuracy: 0.5833\n",
      "Epoch 25/50\n",
      "505/505 [==============================] - 7s 14ms/step - loss: 0.2343 - accuracy: 0.8275 - val_loss: 1.3323 - val_accuracy: 0.6082\n",
      "Epoch 26/50\n",
      "505/505 [==============================] - 8s 16ms/step - loss: 0.2164 - accuracy: 0.8486 - val_loss: 1.5012 - val_accuracy: 0.5663\n",
      "Epoch 27/50\n",
      "505/505 [==============================] - 8s 15ms/step - loss: 0.2180 - accuracy: 0.8387 - val_loss: 1.2156 - val_accuracy: 0.6210\n",
      "Epoch 28/50\n",
      "505/505 [==============================] - 8s 15ms/step - loss: 0.2335 - accuracy: 0.8274 - val_loss: 1.3884 - val_accuracy: 0.5037\n",
      "Epoch 29/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.2783 - accuracy: 0.7913 - val_loss: 1.0015 - val_accuracy: 0.6365\n",
      "Epoch 30/50\n",
      "505/505 [==============================] - 6s 11ms/step - loss: 0.3555 - accuracy: 0.7789 - val_loss: 1.0397 - val_accuracy: 0.5959\n",
      "Epoch 31/50\n",
      "505/505 [==============================] - 6s 13ms/step - loss: 0.2871 - accuracy: 0.7911 - val_loss: 1.3227 - val_accuracy: 0.6213\n",
      "Epoch 32/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.1890 - accuracy: 0.8668 - val_loss: 1.5544 - val_accuracy: 0.5657\n",
      "Epoch 33/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.2123 - accuracy: 0.8414 - val_loss: 1.2477 - val_accuracy: 0.6706\n",
      "Epoch 34/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.2117 - accuracy: 0.8468 - val_loss: 1.2283 - val_accuracy: 0.6494\n",
      "Epoch 35/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.3470 - accuracy: 0.6504 - val_loss: 1.6336 - val_accuracy: 0.4326\n",
      "Epoch 36/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.2653 - accuracy: 0.7875 - val_loss: 1.3670 - val_accuracy: 0.6247\n",
      "Epoch 37/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.2005 - accuracy: 0.8770 - val_loss: 1.2170 - val_accuracy: 0.6683\n",
      "Epoch 38/50\n",
      "505/505 [==============================] - 6s 11ms/step - loss: 0.2706 - accuracy: 0.7919 - val_loss: 1.2711 - val_accuracy: 0.5241\n",
      "Epoch 39/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.2528 - accuracy: 0.8015 - val_loss: 1.3896 - val_accuracy: 0.6664\n",
      "Epoch 40/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.1869 - accuracy: 0.8694 - val_loss: 1.4972 - val_accuracy: 0.6436\n",
      "Epoch 41/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.3094 - accuracy: 0.7973 - val_loss: 1.3599 - val_accuracy: 0.6773\n",
      "Epoch 42/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.2316 - accuracy: 0.8180 - val_loss: 1.2866 - val_accuracy: 0.6060\n",
      "Epoch 43/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.2613 - accuracy: 0.7851 - val_loss: 1.2742 - val_accuracy: 0.3871\n",
      "Epoch 44/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.3091 - accuracy: 0.7237 - val_loss: 1.3079 - val_accuracy: 0.5430\n",
      "Epoch 45/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.2331 - accuracy: 0.8236 - val_loss: 1.2559 - val_accuracy: 0.6332\n",
      "Epoch 46/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.2555 - accuracy: 0.8180 - val_loss: 1.1815 - val_accuracy: 0.6384\n",
      "Epoch 47/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.1994 - accuracy: 0.8673 - val_loss: 3.0197 - val_accuracy: 0.3175\n",
      "Epoch 48/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.2507 - accuracy: 0.8054 - val_loss: 1.3444 - val_accuracy: 0.6378\n",
      "Epoch 49/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.2221 - accuracy: 0.8315 - val_loss: 1.4193 - val_accuracy: 0.6388\n",
      "Epoch 50/50\n",
      "505/505 [==============================] - 6s 12ms/step - loss: 0.2388 - accuracy: 0.8318 - val_loss: 1.3137 - val_accuracy: 0.6112\n"
     ]
    }
   ],
   "source": [
    "mlp = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_prob = model.predict(selected_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "prediction_index = np.argmax(prediction_prob, axis=1)\n",
    "ratings = np.array([3.0, 4.0, 5.0])\n",
    "prediction = ratings[prediction_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({'rating_label': prediction})\n",
    "output_df.index += 1\n",
    "output_df.index.name = 'id'\n",
    "output_df.to_csv('./predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
