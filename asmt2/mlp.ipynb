{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# import librart\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "import feature_select\n",
    "import feture_process\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.sparse import load_npz\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use countvectorizer\n",
    "# use countvectorizer\n",
    "# use countvectorizer\n",
    "# use countvectorizer\n",
    "\n",
    "# import data\n",
    "train_df = pd.read_csv(\"./project_data_files/book_rating_train.csv\")\n",
    "test_df = pd.read_csv(\"./project_data_files/book_rating_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process Prublisher and Language\n",
    "train_df[\"Language\"], test_df[\"Language\"] = feture_process.docclass_preprocess(train_df[\"Language\"],test_df[\"Language\"],10)\n",
    "train_df[\"Publisher\"], test_df[\"Publisher\"] = feture_process.docclass_preprocess(train_df[\"Publisher\"],test_df[\"Publisher\"],200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use oneHotCode for Publisher (sklearn)\n",
    "publisher_train_hot = feture_process.process_OneHotEncoder(train_df,\"Publisher\")\n",
    "publisher_test_hot = feture_process.process_OneHotEncoder(test_df,\"Publisher\")\n",
    "train_df = pd.concat([train_df, publisher_train_hot], axis=1)\n",
    "test_df = pd.concat([test_df, publisher_test_hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use oneHotCode for Language (sklearn)\n",
    "language_train_hot = feture_process.process_OneHotEncoder(train_df,\"Language\")\n",
    "language_test_hot = feture_process.process_OneHotEncoder(test_df,\"Language\")\n",
    "train_df = pd.concat([train_df, language_train_hot], axis=1)\n",
    "test_df = pd.concat([test_df, language_test_hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use oneHotCode for label (sklearn)\n",
    "label_train_hot = feture_process.process_OneHotEncoder(train_df,\"rating_label\")\n",
    "train_df = pd.concat([train_df, label_train_hot], axis=1)\n",
    "train_df = train_df.drop(columns=[\"rating_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_name_countvectorizer\n",
    "train_name_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_name_countvectorizer.pkl\", \"rb\"))\n",
    "train_name_dic = train_name_countvectorizer.vocabulary_\n",
    "\n",
    "# train_authors_countvectorizer\n",
    "train_authors_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_authors_countvectorizer.pkl\", \"rb\"))\n",
    "train_authors_dic = train_authors_countvectorizer.vocabulary_\n",
    "\n",
    "# train_desc_countvectorizer\n",
    "train_desc_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_desc_countvectorizer.pkl\", \"rb\"))\n",
    "train_desc__dic = train_desc_countvectorizer.vocabulary_\n",
    "\n",
    "# process vector features\n",
    "train_name_features = train_name_countvectorizer.transform(train_df['Name'])\n",
    "train_authors_features = train_authors_countvectorizer.transform(train_df['Authors'])\n",
    "train_desc_features = train_desc_countvectorizer.transform(train_df['Description'])\n",
    "other_features_df = train_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new sparse features\n",
    "sparse_features = hstack([train_name_features, train_authors_features, train_desc_features])\n",
    "# new train features\n",
    "dense_features = csr_matrix(other_features_df.values)\n",
    "train_features = hstack([sparse_features, dense_features])\n",
    "\n",
    "\n",
    "# process test features\n",
    "test_name_features = scipy.sparse.load_npz('./project_data_files/book_text_features_countvec/test_name_vec.npz')\n",
    "test_authors_features = scipy.sparse.load_npz('./project_data_files/book_text_features_countvec/test_authors_vec.npz')\n",
    "test_desc_features = scipy.sparse.load_npz('./project_data_files/book_text_features_countvec/test_desc_vec.npz')\n",
    "test_other_features_df = test_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language'])\n",
    "\n",
    "test_sparse_features = hstack([test_name_features, test_authors_features, test_desc_features])\n",
    "new_dense_features = csr_matrix(test_other_features_df.values)\n",
    "test_features = hstack([test_sparse_features, new_dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features,selected_features_test = feature_select.MI(train_df,train_features,test_features,12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = load_npz(\"selected_features_label_one_hot_12000.npz\")\n",
    "selected_features_test = load_npz(\"selected_features_test_label_one_hot_12000.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "input_dim = selected_features.shape[1] \n",
    "num_classes = label_train_hot.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(40, activation='relu', input_shape=(input_dim,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(selected_features, label_train_hot, test_size=0.3, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.toarray()\n",
    "X_val = X_val.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "505/505 [==============================] - 2s 4ms/step - loss: 0.9357 - accuracy: 0.6797 - val_loss: 0.7094 - val_accuracy: 0.7211\n",
      "Epoch 2/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.6488 - accuracy: 0.7228 - val_loss: 0.7375 - val_accuracy: 0.6774\n",
      "Epoch 3/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.5920 - accuracy: 0.7449 - val_loss: 0.6910 - val_accuracy: 0.7260\n",
      "Epoch 4/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.5480 - accuracy: 0.7641 - val_loss: 0.6858 - val_accuracy: 0.7057\n",
      "Epoch 5/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.5066 - accuracy: 0.7862 - val_loss: 0.6883 - val_accuracy: 0.6932\n",
      "Epoch 6/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.4683 - accuracy: 0.7986 - val_loss: 0.6778 - val_accuracy: 0.7252\n",
      "Epoch 7/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.4271 - accuracy: 0.8193 - val_loss: 0.6984 - val_accuracy: 0.7403\n",
      "Epoch 8/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.3901 - accuracy: 0.8368 - val_loss: 0.9732 - val_accuracy: 0.5450\n",
      "Epoch 9/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.3769 - accuracy: 0.8380 - val_loss: 0.8133 - val_accuracy: 0.7357\n",
      "Epoch 10/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.3534 - accuracy: 0.8511 - val_loss: 0.8353 - val_accuracy: 0.6765\n",
      "Epoch 11/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.3115 - accuracy: 0.8682 - val_loss: 0.8630 - val_accuracy: 0.7384\n",
      "Epoch 12/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.2856 - accuracy: 0.8803 - val_loss: 0.8446 - val_accuracy: 0.7219\n",
      "Epoch 13/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.2767 - accuracy: 0.8835 - val_loss: 0.9247 - val_accuracy: 0.7081\n",
      "Epoch 14/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.2883 - accuracy: 0.8764 - val_loss: 0.9392 - val_accuracy: 0.7161\n",
      "Epoch 15/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.2749 - accuracy: 0.8837 - val_loss: 1.1928 - val_accuracy: 0.7342\n",
      "Epoch 16/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.2462 - accuracy: 0.8987 - val_loss: 0.9476 - val_accuracy: 0.7092\n",
      "Epoch 17/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.2377 - accuracy: 0.8987 - val_loss: 1.0988 - val_accuracy: 0.7328\n",
      "Epoch 18/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.2155 - accuracy: 0.9091 - val_loss: 1.0517 - val_accuracy: 0.7216\n",
      "Epoch 19/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.2182 - accuracy: 0.9086 - val_loss: 1.2065 - val_accuracy: 0.6988\n",
      "Epoch 20/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1943 - accuracy: 0.9208 - val_loss: 1.1583 - val_accuracy: 0.6966\n",
      "Epoch 21/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.2001 - accuracy: 0.9175 - val_loss: 1.2784 - val_accuracy: 0.7242\n",
      "Epoch 22/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1877 - accuracy: 0.9228 - val_loss: 1.2898 - val_accuracy: 0.7166\n",
      "Epoch 23/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1730 - accuracy: 0.9275 - val_loss: 1.4081 - val_accuracy: 0.7287\n",
      "Epoch 24/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1676 - accuracy: 0.9293 - val_loss: 1.3384 - val_accuracy: 0.6303\n",
      "Epoch 25/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1597 - accuracy: 0.9330 - val_loss: 1.7646 - val_accuracy: 0.7380\n",
      "Epoch 26/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1724 - accuracy: 0.9320 - val_loss: 1.3565 - val_accuracy: 0.7027\n",
      "Epoch 27/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1547 - accuracy: 0.9373 - val_loss: 1.4218 - val_accuracy: 0.6472\n",
      "Epoch 28/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1688 - accuracy: 0.9311 - val_loss: 1.5750 - val_accuracy: 0.6971\n",
      "Epoch 29/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1615 - accuracy: 0.9341 - val_loss: 1.4261 - val_accuracy: 0.6796\n",
      "Epoch 30/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1359 - accuracy: 0.9435 - val_loss: 1.4370 - val_accuracy: 0.7237\n",
      "Epoch 31/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1345 - accuracy: 0.9465 - val_loss: 1.4983 - val_accuracy: 0.7263\n",
      "Epoch 32/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1249 - accuracy: 0.9492 - val_loss: 1.6843 - val_accuracy: 0.7186\n",
      "Epoch 33/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1215 - accuracy: 0.9508 - val_loss: 1.7641 - val_accuracy: 0.6499\n",
      "Epoch 34/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1433 - accuracy: 0.9427 - val_loss: 1.6927 - val_accuracy: 0.7141\n",
      "Epoch 35/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1186 - accuracy: 0.9534 - val_loss: 1.7263 - val_accuracy: 0.6868\n",
      "Epoch 36/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1030 - accuracy: 0.9590 - val_loss: 2.0739 - val_accuracy: 0.7241\n",
      "Epoch 37/50\n",
      "505/505 [==============================] - 2s 4ms/step - loss: 0.1336 - accuracy: 0.9480 - val_loss: 1.8407 - val_accuracy: 0.7320\n",
      "Epoch 38/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1672 - accuracy: 0.9305 - val_loss: 2.1718 - val_accuracy: 0.7303\n",
      "Epoch 39/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1304 - accuracy: 0.9473 - val_loss: 1.5819 - val_accuracy: 0.6822\n",
      "Epoch 40/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1121 - accuracy: 0.9566 - val_loss: 1.9049 - val_accuracy: 0.7320\n",
      "Epoch 41/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.0934 - accuracy: 0.9648 - val_loss: 1.9056 - val_accuracy: 0.6963\n",
      "Epoch 42/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1003 - accuracy: 0.9592 - val_loss: 2.2756 - val_accuracy: 0.7118\n",
      "Epoch 43/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.0900 - accuracy: 0.9657 - val_loss: 1.9269 - val_accuracy: 0.7085\n",
      "Epoch 44/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.0841 - accuracy: 0.9672 - val_loss: 2.0616 - val_accuracy: 0.7176\n",
      "Epoch 45/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1031 - accuracy: 0.9637 - val_loss: 2.2037 - val_accuracy: 0.7085\n",
      "Epoch 46/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1040 - accuracy: 0.9590 - val_loss: 2.1398 - val_accuracy: 0.7273\n",
      "Epoch 47/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.0824 - accuracy: 0.9677 - val_loss: 1.5492 - val_accuracy: 0.6709\n",
      "Epoch 48/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.0942 - accuracy: 0.9651 - val_loss: 1.8587 - val_accuracy: 0.7271\n",
      "Epoch 49/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.1049 - accuracy: 0.9589 - val_loss: 2.0749 - val_accuracy: 0.7028\n",
      "Epoch 50/50\n",
      "505/505 [==============================] - 2s 3ms/step - loss: 0.0612 - accuracy: 0.9773 - val_loss: 2.1888 - val_accuracy: 0.6781\n"
     ]
    }
   ],
   "source": [
    "mlp = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_prob = model.predict(selected_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "prediction_index = np.argmax(prediction_prob, axis=1)\n",
    "ratings = np.array([3.0, 4.0, 5.0])\n",
    "prediction = ratings[prediction_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({'rating_label': prediction})\n",
    "output_df.index += 1\n",
    "output_df.index.name = 'id'\n",
    "output_df.to_csv('./predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
