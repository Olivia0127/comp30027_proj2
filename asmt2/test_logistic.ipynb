{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb85cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import sklearn\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31858daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train_df = pd.read_csv(\"./project_data_files/book_rating_train.csv\")\n",
    "test_df = pd.read_csv(\"./project_data_files/book_rating_test.csv\")\n",
    "\n",
    "# train_name_countvectorizer\n",
    "train_name_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_name_countvectorizer.pkl\", \"rb\"))\n",
    "train_name_dic = train_name_countvectorizer.vocabulary_\n",
    "\n",
    "# train_authors_countvectorizer\n",
    "train_authors_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_authors_countvectorizer.pkl\", \"rb\"))\n",
    "train_authors_dic = train_authors_countvectorizer.vocabulary_\n",
    "\n",
    "# train_desc_countvectorizer\n",
    "train_desc_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_desc_countvectorizer.pkl\", \"rb\"))\n",
    "train_desc__dic = train_desc_countvectorizer.vocabulary_\n",
    "\n",
    "# process vector features\n",
    "train_name_features = train_name_countvectorizer.transform(train_df['Name'])\n",
    "train_authors_features = train_authors_countvectorizer.transform(train_df['Authors'])\n",
    "train_desc_features = train_desc_countvectorizer.transform(train_df['Description'])\n",
    "other_features_df_train = train_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language', 'rating_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "96f78e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x2_feature_selection(X_train, X_test, y_train, feature_num):\n",
    "    x2 = SelectKBest(chi2, k=feature_num)\n",
    "    X_train_x2 = x2.fit_transform(X_train,y_train)\n",
    "    X_test_x2 = x2.transform(X_test)\n",
    "    return X_train_x2, X_test_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ca4cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process for test set\n",
    "test_name_features = train_name_countvectorizer.transform(test_df['Name'])\n",
    "test_authors_features = train_authors_countvectorizer.transform(test_df['Authors'])\n",
    "test_desc_features = train_desc_countvectorizer.transform(test_df['Description'])\n",
    "other_features_df_test = test_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50b3c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do feature selection\n",
    "y_train = train_df['rating_label']\n",
    "\n",
    "train_name_countvec_x2, test_name_countvec_x2= x2_feature_selection(train_name_features, test_name_features, y_train, 100)\n",
    "train_author_countvec_x2, test_author_countvec_x2 = x2_feature_selection(train_authors_features, test_authors_features, y_train, 20)\n",
    "train_desc_countvec_x2, test_desc_countvec_x2 = x2_feature_selection(train_desc_features, test_desc_features, y_train, 100)\n",
    "\n",
    "# new sparse features\n",
    "sparse_features_train_countvec = hstack([train_name_countvec_x2, train_author_countvec_x2, train_desc_countvec_x2])\n",
    "sparse_features_test_countvec = hstack([test_name_countvec_x2, test_author_countvec_x2, test_desc_countvec_x2])\n",
    "\n",
    "# new train features\n",
    "dense_features_train = csr_matrix(other_features_df_train.values)\n",
    "dense_features_test = csr_matrix(other_features_df_test.values)\n",
    "\n",
    "#combine all features\n",
    "X_test = hstack([sparse_features, dense_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6616230",
   "metadata": {},
   "source": [
    "next several blocks are for doc2vec transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8779fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process vector features\n",
    "train_name_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/train_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "train_authors_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/train_authors_doc2vec20.csv\", index_col = False, delimiter = ',', header=None)\n",
    "train_desc_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/train_desc_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "other_features_df = train_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language', 'rating_label'])\n",
    "train_features_docvec = pd.concat([train_name_features, train_authors_features, train_desc_features], axis=1)\n",
    "dense_features_train_docvec = csr_matrix(train_features_docvec.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf844ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process test features\n",
    "test_name_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/test_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_authors_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/test_authors_doc2vec20.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_desc_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/test_desc_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_features_docvec = pd.concat([test_name_features, test_authors_features, test_desc_features], axis=1)\n",
    "dense_features_test_docvec = csr_matrix(test_features_docvec.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "da0caba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23063, 220)\n"
     ]
    }
   ],
   "source": [
    "# new train features\n",
    "train_features = hstack([sparse_features_train_countvec, dense_features_train, dense_features_train_docvec])\n",
    "X_test = hstack([sparse_features_test_countvec, dense_features_test, dense_features_test_docvec])\n",
    "print(sparse_features_train_countvec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00e4c2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18450, 444)\n"
     ]
    }
   ],
   "source": [
    "# split train and testing dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_df[\"rating_label\"], test_size=0.2, random_state=42)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f387e3c4",
   "metadata": {},
   "source": [
    "def a function to help output result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0fcb7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_predictions(prediction):\n",
    "    #output result\n",
    "    output_df = pd.DataFrame({'rating_label': prediction})\n",
    "    output_df.index += 1\n",
    "    output_df.index.name = 'id'\n",
    "    output_df.to_csv('./predictions.csv')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ffab0b",
   "metadata": {},
   "source": [
    "then fit for two model to evaluate the feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d5879c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7132018209408194\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train,y_train)\n",
    "print(\"Accuracy:\",lgr.score(X_val,y_val))\n",
    "presiction_logistic = lgr.predict(X_test)\n",
    "output_predictions(prediction_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302f2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {'max_iter': [100, 500, 1000, 2000, 3000, 5000]}\n",
    "\n",
    "# Create a logistic regression classifier\n",
    "lgr = LogisticRegression()\n",
    "\n",
    "\n",
    "# Use GridSearchCV to find the best max_iter value\n",
    "grid_search = GridSearchCV(lgr, param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and accuracy score\n",
    "print(\"Best max_iter value:\", grid_search.best_params_['max_iter'])\n",
    "print(\"Accuracy:\", grid_search.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a7468",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_logistic_grid = grid_search.predict(X_test)\n",
    "output_predictions(prediction_logistic_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08d93c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.708649468892261\n"
     ]
    }
   ],
   "source": [
    "#try a svm model\n",
    "C = 1.0\n",
    "SVM_classifier = svm.SVC(kernel='rbf', gamma=0.7, C=C)\n",
    "SVM_classifier.fit(X_train, y_train)\n",
    "print(SVM_classifier.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3299dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try polynomial kernel for svm\n",
    "#svm_poly = svm.SVC(kernel='poly', degree=3, gamma='auto', C=C))\n",
    "#svm_poly.fit(X_train_x2, y_train)\n",
    "#print(svm_poly.score(X_val_x2, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "920a96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_svm = SVM_classifier.predict(X_test_x2)\n",
    "output_predictions(prediction_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bbf010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
