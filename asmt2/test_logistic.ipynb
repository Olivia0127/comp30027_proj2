{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb85cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import sklearn\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31858daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18450, 126889)\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "train_df = pd.read_csv(\"./project_data_files/book_rating_train.csv\")\n",
    "test_df = pd.read_csv(\"./project_data_files/book_rating_test.csv\")\n",
    "\n",
    "# train_name_countvectorizer\n",
    "train_name_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_name_countvectorizer.pkl\", \"rb\"))\n",
    "train_name_dic = train_name_countvectorizer.vocabulary_\n",
    "\n",
    "# train_authors_countvectorizer\n",
    "train_authors_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_authors_countvectorizer.pkl\", \"rb\"))\n",
    "train_authors_dic = train_authors_countvectorizer.vocabulary_\n",
    "\n",
    "# train_desc_countvectorizer\n",
    "train_desc_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_desc_countvectorizer.pkl\", \"rb\"))\n",
    "train_desc__dic = train_desc_countvectorizer.vocabulary_\n",
    "\n",
    "# process vector features\n",
    "train_name_features = train_name_countvectorizer.transform(train_df['Name'])\n",
    "train_authors_features = train_authors_countvectorizer.transform(train_df['Authors'])\n",
    "train_desc_features = train_desc_countvectorizer.transform(train_df['Description'])\n",
    "other_features_df = train_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language'])\n",
    "# new sparse features\n",
    "sparse_features = hstack([train_name_features, train_authors_features, train_desc_features])\n",
    "# new train features\n",
    "dense_features = csr_matrix(other_features_df.values)\n",
    "train_features = hstack([sparse_features, dense_features])\n",
    "\n",
    "# split train and testing dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_df[\"rating_label\"], test_size=0.2, random_state=42)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ee1b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18450, 100)\n"
     ]
    }
   ],
   "source": [
    "x2 = SelectKBest(chi2, k=100)\n",
    "\n",
    "X_train_x2 = x2.fit_transform(X_train,y_train)\n",
    "X_val_x2 = x2.transform(X_val)\n",
    "print(X_train_x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fca8af40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9436375460654671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train,y_train)\n",
    "print(\"Accuracy:\",lgr.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "573788b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9273791458920442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train_x2,y_train)\n",
    "print(\"Accuracy:\",lgr.score(X_val_x2,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a19a971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_iter value: 5000\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {'max_iter': [100, 500, 1000, 5000, 10000, 20000]}\n",
    "\n",
    "# Create a logistic regression classifier\n",
    "lgr = LogisticRegression()\n",
    "\n",
    "\n",
    "# Use GridSearchCV to find the best max_iter value\n",
    "grid_search = GridSearchCV(lgr, param_grid, cv=3)\n",
    "grid_search.fit(X_train_x2, y_train)\n",
    "\n",
    "# Print the best parameters and accuracy score\n",
    "print(\"Best max_iter value:\", grid_search.best_params_['max_iter'])\n",
    "print(\"Accuracy:\", grid_search.score(X_val_x2, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d9819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
