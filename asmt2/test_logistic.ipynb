{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb85cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import sklearn\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31858daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train_df = pd.read_csv(\"./project_data_files/book_rating_train.csv\")\n",
    "test_df = pd.read_csv(\"./project_data_files/book_rating_test.csv\")\n",
    "\n",
    "# train_name_countvectorizer\n",
    "train_name_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_name_countvectorizer.pkl\", \"rb\"))\n",
    "train_name_dic = train_name_countvectorizer.vocabulary_\n",
    "\n",
    "# train_authors_countvectorizer\n",
    "train_authors_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_authors_countvectorizer.pkl\", \"rb\"))\n",
    "train_authors_dic = train_authors_countvectorizer.vocabulary_\n",
    "\n",
    "# train_desc_countvectorizer\n",
    "train_desc_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_desc_countvectorizer.pkl\", \"rb\"))\n",
    "train_desc__dic = train_desc_countvectorizer.vocabulary_\n",
    "\n",
    "# process vector features\n",
    "train_name_features = train_name_countvectorizer.transform(train_df['Name'])\n",
    "train_authors_features = train_authors_countvectorizer.transform(train_df['Authors'])\n",
    "train_desc_features = train_desc_countvectorizer.transform(train_df['Description'])\n",
    "other_features_df_train = train_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language', 'rating_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f78e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x2_feature_selection(X_train, X_test, y_train, feature_num):\n",
    "    x2 = SelectKBest(chi2, k=feature_num)\n",
    "    X_train_x2 = x2.fit_transform(X_train,y_train)\n",
    "    X_test_x2 = x2.transform(X_test)\n",
    "    return X_train_x2, X_test_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca4cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process for test set\n",
    "test_name_features = train_name_countvectorizer.transform(test_df['Name'])\n",
    "test_authors_features = train_authors_countvectorizer.transform(test_df['Authors'])\n",
    "test_desc_features = train_desc_countvectorizer.transform(test_df['Description'])\n",
    "other_features_df_test = test_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b3c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do feature selection\n",
    "y_train = train_df['rating_label']\n",
    "\n",
    "train_name_countvec_x2, test_name_countvec_x2= x2_feature_selection(train_name_features, test_name_features, y_train, 100)\n",
    "train_author_countvec_x2, test_author_countvec_x2 = x2_feature_selection(train_authors_features, test_authors_features, y_train, 20)\n",
    "train_desc_countvec_x2, test_desc_countvec_x2 = x2_feature_selection(train_desc_features, test_desc_features, y_train, 100)\n",
    "\n",
    "# new sparse features\n",
    "sparse_features_train_countvec = hstack([train_name_countvec_x2, train_author_countvec_x2, train_desc_countvec_x2])\n",
    "sparse_features_test_countvec = hstack([test_name_countvec_x2, test_author_countvec_x2, test_desc_countvec_x2])\n",
    "\n",
    "# new train features\n",
    "dense_features_train = csr_matrix(other_features_df_train.values)\n",
    "dense_features_test = csr_matrix(other_features_df_test.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6616230",
   "metadata": {},
   "source": [
    "next several blocks are for doc2vec transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8779fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process vector features\n",
    "train_name_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/train_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "train_authors_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/train_authors_doc2vec20.csv\", index_col = False, delimiter = ',', header=None)\n",
    "train_desc_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/train_desc_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "other_features_df = train_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language', 'rating_label'])\n",
    "train_features_docvec = pd.concat([train_name_features, train_authors_features, train_desc_features], axis=1)\n",
    "dense_features_train_docvec = csr_matrix(train_features_docvec.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf844ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process test features\n",
    "test_name_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/test_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_authors_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/test_authors_doc2vec20.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_desc_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/test_desc_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_features_docvec = pd.concat([test_name_features, test_authors_features, test_desc_features], axis=1)\n",
    "dense_features_test_docvec = csr_matrix(test_features_docvec.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da0caba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23063, 220)\n"
     ]
    }
   ],
   "source": [
    "# new train features\n",
    "train_features = hstack([sparse_features_train_countvec, dense_features_train, dense_features_train_docvec])\n",
    "X_test = hstack([sparse_features_test_countvec, dense_features_test, dense_features_test_docvec])\n",
    "print(sparse_features_train_countvec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00e4c2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18450, 444)\n",
      "  (0, 206)\t1.0\n",
      "  (0, 220)\t1993.0\n",
      "  (0, 221)\t6.0\n",
      "  (0, 222)\t1.0\n",
      "  (0, 223)\t398.0\n",
      "  (0, 224)\t-0.06392902880907059\n",
      "  (0, 225)\t0.12211732566356658\n",
      "  (0, 226)\t-0.009757831692695616\n",
      "  (0, 227)\t0.07373512536287308\n",
      "  (0, 228)\t-0.006081403698772192\n",
      "  (0, 229)\t-0.01131432130932808\n",
      "  (0, 230)\t0.00944425631314516\n",
      "  (0, 231)\t0.14090394973754883\n",
      "  (0, 232)\t-0.03458491712808609\n",
      "  (0, 233)\t-0.031706225126981735\n",
      "  (0, 234)\t-0.18284228444099423\n",
      "  (0, 235)\t0.003114692401140928\n",
      "  (0, 236)\t-0.11357323080301283\n",
      "  (0, 237)\t-0.08756700903177261\n",
      "  (0, 238)\t0.12100431323051453\n",
      "  (0, 239)\t-0.04909089207649231\n",
      "  (0, 240)\t0.0918167605996132\n",
      "  (0, 241)\t-0.07013675570487976\n",
      "  (0, 242)\t-0.15027473866939545\n",
      "  (0, 243)\t-0.22050502896308896\n",
      "  :\t:\n",
      "  (18449, 419)\t1.019339084625244\n",
      "  (18449, 420)\t-0.10736381262540816\n",
      "  (18449, 421)\t-0.6075002551078796\n",
      "  (18449, 422)\t-0.4448202550411224\n",
      "  (18449, 423)\t-0.6948765516281128\n",
      "  (18449, 424)\t-1.7883001565933228\n",
      "  (18449, 425)\t-0.03296919912099838\n",
      "  (18449, 426)\t0.24415245652198792\n",
      "  (18449, 427)\t1.8556331396102903\n",
      "  (18449, 428)\t-0.8568676114082336\n",
      "  (18449, 429)\t-0.12221703678369522\n",
      "  (18449, 430)\t0.6011924147605896\n",
      "  (18449, 431)\t0.2633152902126312\n",
      "  (18449, 432)\t0.442316859960556\n",
      "  (18449, 433)\t-1.2847976684570312\n",
      "  (18449, 434)\t0.9247593879699709\n",
      "  (18449, 435)\t0.9511630535125731\n",
      "  (18449, 436)\t0.6190539002418518\n",
      "  (18449, 437)\t0.3243580162525177\n",
      "  (18449, 438)\t0.6644744873046875\n",
      "  (18449, 439)\t-0.5056400895118712\n",
      "  (18449, 440)\t-0.6832414269447327\n",
      "  (18449, 441)\t-0.4303314387798309\n",
      "  (18449, 442)\t0.8348333835601807\n",
      "  (18449, 443)\t2.093913078308105\n"
     ]
    }
   ],
   "source": [
    "# split train and testing dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_df[\"rating_label\"], test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f387e3c4",
   "metadata": {},
   "source": [
    "def a function to help output result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fcb7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_predictions(prediction):\n",
    "    #output result\n",
    "    output_df = pd.DataFrame({'rating_label': prediction})\n",
    "    output_df.index += 1\n",
    "    output_df.index.name = 'id'\n",
    "    output_df.to_csv('./predictions.csv')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ffab0b",
   "metadata": {},
   "source": [
    "then fit for two model to evaluate the feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5879c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7132018209408194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olivia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train,y_train)\n",
    "print(\"Accuracy:\",lgr.score(X_val,y_val))\n",
    "prediction_logistic = lgr.predict(X_test)\n",
    "output_predictions(prediction_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302f2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_iter value: 5000\n",
      "Accuracy: 0.7127682636028615\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {'max_iter': [100, 500, 1000, 2000, 3000, 5000]}\n",
    "\n",
    "# Create a logistic regression classifier\n",
    "lgr = LogisticRegression()\n",
    "\n",
    "\n",
    "# Use GridSearchCV to find the best max_iter value\n",
    "grid_search = GridSearchCV(lgr, param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and accuracy score\n",
    "print(\"Best max_iter value:\", grid_search.best_params_['max_iter'])\n",
    "print(\"Accuracy:\", grid_search.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a7468",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_logistic_grid = grid_search.predict(X_test)\n",
    "output_predictions(prediction_logistic_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d93c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7112508129200087\n"
     ]
    }
   ],
   "source": [
    "#try a svm model\n",
    "C = 1.0\n",
    "SVM_classifier = svm.SVC(kernel='rbf', gamma=0.7, C=C)\n",
    "SVM_classifier.fit(X_train, y_train)\n",
    "print(SVM_classifier.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf43ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_svm = SVM_classifier.predict(X_test)\n",
    "output_predictions(prediction_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3299dd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7140689356167353\n"
     ]
    }
   ],
   "source": [
    "#try polynomial kernel for svm\n",
    "C = 1.0\n",
    "svm_linear = svm.SVC(kernel='linear', C=C)\n",
    "svm_linear.fit(X_train, y_train)\n",
    "print(svm_linear.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97bbf010",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_svm_poly = svm_poly.predict(X_test)\n",
    "output_predictions(prediction_svm_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1749148a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
