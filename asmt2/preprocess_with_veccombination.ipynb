{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import sklearn\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import save_npz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train_df = pd.read_csv(\"./project_data_files/book_rating_train.csv\")\n",
    "test_df = pd.read_csv(\"./project_data_files/book_rating_test.csv\")\n",
    "\n",
    "# train_name_countvectorizer\n",
    "train_name_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_name_countvectorizer.pkl\", \"rb\"))\n",
    "train_name_dic = train_name_countvectorizer.vocabulary_\n",
    "\n",
    "# train_authors_countvectorizer\n",
    "train_authors_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_authors_countvectorizer.pkl\", \"rb\"))\n",
    "train_authors_dic = train_authors_countvectorizer.vocabulary_\n",
    "\n",
    "# train_desc_countvectorizer\n",
    "train_desc_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_desc_countvectorizer.pkl\", \"rb\"))\n",
    "train_desc__dic = train_desc_countvectorizer.vocabulary_\n",
    "\n",
    "# process vector features\n",
    "train_name_features = train_name_countvectorizer.transform(train_df['Name'])\n",
    "train_authors_features = train_authors_countvectorizer.transform(train_df['Authors'])\n",
    "train_desc_features = train_desc_countvectorizer.transform(train_df['Description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process for test set\n",
    "test_name_features = train_name_countvectorizer.transform(test_df['Name'])\n",
    "test_authors_features = train_authors_countvectorizer.transform(test_df['Authors'])\n",
    "test_desc_features = train_desc_countvectorizer.transform(test_df['Description'])\n",
    "other_features_df_test = test_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docclass_preprocess(train, test, threshold):\n",
    "    #change some type of class into other to decrease the dimension of matrix\n",
    "    data = train.value_counts()\n",
    "    data_test = test.value_counts()\n",
    "    unfreq_class = []\n",
    "    for cla in data.index:\n",
    "        if data[cla] < threshold:\n",
    "            unfreq_class.append(cla)\n",
    "    for cla in data_test.index:\n",
    "        if cla not in data.index:\n",
    "            test = test.replace(cla, 'others')\n",
    "    train = train.replace(unfreq_class, 'others')\n",
    "    train.fillna('others', inplace = True)\n",
    "    test = test.replace(unfreq_class, 'others')\n",
    "    test.fillna('others', inplace = True)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23063, 25)\n"
     ]
    }
   ],
   "source": [
    "#preprocess two features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "train_df['Language'], test_df['Language'] = docclass_preprocess(train_df['Language'], test_df['Language'], 50)\n",
    "train_df['Publisher'], test_df['Publisher'] = docclass_preprocess(train_df['Publisher'], test_df['Publisher'], 100)\n",
    "train_df_spec = train_df[['Language', 'Publisher']]\n",
    "test_df_spec = test_df[['Language', 'Publisher']]\n",
    "train_num_spec = ohe.fit_transform(train_df_spec)\n",
    "test_num_spec = ohe.transform(test_df_spec)\n",
    "print(train_num_spec.shape)\n",
    "#train_spec = csr_matrix(train_df_spec.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features_df_train = train_df.drop(columns=['Name', 'Authors', 'Publisher', 'Language', 'Description', 'rating_label'])\n",
    "other_features_df_test = test_df.drop(columns=['Name', 'Authors', 'Publisher', 'Language', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x2_feature_selection(X_train, X_test, y_train, feature_num):\n",
    "    x2 = SelectKBest(chi2, k=feature_num)\n",
    "    X_train_x2 = x2.fit_transform(X_train,y_train)\n",
    "    X_test_x2 = x2.transform(X_test)\n",
    "    return X_train_x2, X_test_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutualInformation selection\n",
    "def mi_feature_selection(X_train, X_test, y_train,k):\n",
    "    selector = SelectKBest(mutual_info_classif, k=k)\n",
    "    X_train = selector.fit_transform(X_train, y_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_selection(X_train, X_test, y_train, k):\n",
    "    #use a logistic regression model to do recursive feature elimination\n",
    "    rfe = RFE(estimator=GaussianNB(), n_features_to_select=k)\n",
    "    X_train = rfe.fit_transform(X_train, y_train)\n",
    "    X_test = rfe.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do feature selection\n",
    "y_train = train_df['rating_label']\n",
    "#use chi2 to select count vectors\n",
    "#train_name_countvec_x2, test_name_countvec_x2= x2_feature_selection(train_name_features, test_name_features, y_train, 500)\n",
    "#train_author_countvec_x2, test_author_countvec_x2 = x2_feature_selection(train_authors_features, test_authors_features, y_train, 200)\n",
    "#train_desc_countvec_x2, test_desc_countvec_x2 = x2_feature_selection(train_desc_features, test_desc_features, y_train, 10000)\n",
    "\n",
    "#use mi to select count vectors\n",
    "train_name_countvec_mi, test_name_countvec_mi= mi_feature_selection(train_name_features, test_name_features, y_train, 50)\n",
    "train_author_countvec_mi, test_author_countvec_mi = mi_feature_selection(train_authors_features, test_authors_features, y_train, 20)\n",
    "train_desc_countvec_mi, test_desc_countvec_mi = mi_feature_selection(train_desc_features, test_desc_features, y_train, 100)\n",
    "\n",
    "\n",
    "# new sparse features\n",
    "sparse_features_train_countvec = hstack([train_name_countvec_mi, train_author_countvec_mi, train_desc_countvec_mi])\n",
    "sparse_features_test_countvec = hstack([test_name_countvec_mi, test_author_countvec_mi, test_desc_countvec_mi])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new train features\n",
    "dense_features_train = csr_matrix(other_features_df_train)\n",
    "dense_features_test = csr_matrix(other_features_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all to select\n",
    "y_train = train_df['rating_label']\n",
    "sparse_features_train_countvec = hstack([train_name_features, train_authors_features, train_desc_features, train_num_spec, dense_features_train])\n",
    "sparse_features_test_countvec = hstack([test_name_features, test_authors_features, test_desc_features, test_num_spec, dense_features_test])\n",
    "train_features, X_test = x2_feature_selection(sparse_features_train_countvec, sparse_features_test_countvec, y_train, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "norm = Normalizer()\n",
    "train_name_features = norm.fit_transform(train_features)\n",
    "test_name_features = norm.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc_vec transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process vector features\n",
    "train_name_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/train_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "train_authors_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/train_authors_doc2vec20.csv\", index_col = False, delimiter = ',', header=None)\n",
    "train_desc_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/train_desc_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "other_features_df = train_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language', 'rating_label'])\n",
    "train_features_docvec = pd.concat([train_name_features, train_authors_features, train_desc_features], axis=1)\n",
    "dense_features_train_docvec = csr_matrix(train_features_docvec.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process test features\n",
    "test_name_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/test_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_authors_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/test_authors_doc2vec20.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_desc_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/test_desc_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_features_docvec = pd.concat([test_name_features, test_authors_features, test_desc_features], axis=1)\n",
    "dense_features_test_docvec = csr_matrix(test_features_docvec.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine the docvec and countvec together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23063, 5000)\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# new train features\n",
    "#train_features = hstack([dense_features_train, train_num_spec])\n",
    "#X_test = hstack([dense_features_test,test_num_spec])\n",
    "\n",
    "#train_features = train_author_countvec_mi\n",
    "#X_test = test_author_countvec_mi\n",
    "\n",
    "print(train_features.shape)\n",
    "print(type(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output the data preprocessed\n",
    "save_npz('x_train_5000.npz', train_features)\n",
    "save_npz('x_test_5000.npz', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "449056e4a45b52db97e4be0f9eb617c8f7bfc9621aa20fbcd7c2dc4aebf2696f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
