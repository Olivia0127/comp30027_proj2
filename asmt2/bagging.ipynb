{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librart\n",
    "import sklearn\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "import feature_select\n",
    "import feture_process\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.sparse import save_npz\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train_df = pd.read_csv(\"./project_data_files/book_rating_train.csv\")\n",
    "test_df = pd.read_csv(\"./project_data_files/book_rating_test.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot code Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process Prublisher and Language\n",
    "train_df[\"Language\"], test_df[\"Language\"] = feture_process.docclass_preprocess(train_df[\"Language\"],test_df[\"Language\"],10)\n",
    "train_df[\"Publisher\"], test_df[\"Publisher\"] = feture_process.docclass_preprocess(train_df[\"Publisher\"],test_df[\"Publisher\"],200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use oneHotCode for Publisher (sklearn)\n",
    "publisher_train_hot = feture_process.process_OneHotEncoder(train_df,\"Publisher\")\n",
    "publisher_test_hot = feture_process.process_OneHotEncoder(test_df,\"Publisher\")\n",
    "train_df = pd.concat([train_df, publisher_train_hot], axis=1)\n",
    "test_df = pd.concat([test_df, publisher_test_hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use oneHotCode for Language (sklearn)\n",
    "language_train_hot = feture_process.process_OneHotEncoder(train_df,\"Language\")\n",
    "language_test_hot = feture_process.process_OneHotEncoder(test_df,\"Language\")\n",
    "train_df = pd.concat([train_df, language_train_hot], axis=1)\n",
    "test_df = pd.concat([test_df, language_test_hot], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use oneHotCode for Publisher (pandas)\n",
    "publisher_train_hot,publisher_test_hot = feture_process.process_OneHotEncoder_pd(train_df,test_df,\"Publisher\")\n",
    "train_df = pd.concat([train_df, publisher_train_hot], axis=1)\n",
    "test_df = pd.concat([test_df, publisher_test_hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use oneHotCode for Language (pandas)\n",
    "language_train_hot,language_test_hot = feture_process.process_OneHotEncoder_pd(train_df,test_df,\"Language\")\n",
    "train_df = pd.concat([train_df, language_train_hot], axis=1)\n",
    "test_df = pd.concat([test_df, language_test_hot], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countvectorizer processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_name_countvectorizer\n",
    "train_name_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_name_countvectorizer.pkl\", \"rb\"))\n",
    "train_name_dic = train_name_countvectorizer.vocabulary_\n",
    "\n",
    "# train_authors_countvectorizer\n",
    "train_authors_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_authors_countvectorizer.pkl\", \"rb\"))\n",
    "train_authors_dic = train_authors_countvectorizer.vocabulary_\n",
    "\n",
    "# train_desc_countvectorizer\n",
    "train_desc_countvectorizer = pickle.load(open(\"./project_data_files/book_text_features_countvec/train_desc_countvectorizer.pkl\", \"rb\"))\n",
    "train_desc__dic = train_desc_countvectorizer.vocabulary_\n",
    "\n",
    "# process vector features\n",
    "train_name_features = train_name_countvectorizer.transform(train_df['Name'])\n",
    "train_authors_features = train_authors_countvectorizer.transform(train_df['Authors'])\n",
    "train_desc_features = train_desc_countvectorizer.transform(train_df['Description'])\n",
    "other_features_df = train_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language', 'rating_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new train features\n",
    "sparse_features = hstack([train_name_features, train_authors_features, train_desc_features])\n",
    "dense_features = csr_matrix(other_features_df.values)\n",
    "train_features = hstack([sparse_features, dense_features])\n",
    "\n",
    "\n",
    "# process test features\n",
    "test_name_features = scipy.sparse.load_npz('./project_data_files/book_text_features_countvec/test_name_vec.npz')\n",
    "test_authors_features = scipy.sparse.load_npz('./project_data_files/book_text_features_countvec/test_authors_vec.npz')\n",
    "test_desc_features = scipy.sparse.load_npz('./project_data_files/book_text_features_countvec/test_desc_vec.npz')\n",
    "test_other_features_df = test_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language'])\n",
    "\n",
    "test_sparse_features = hstack([test_name_features, test_authors_features, test_desc_features])\n",
    "new_dense_features = csr_matrix(test_other_features_df.values)\n",
    "test_features = hstack([test_sparse_features, new_dense_features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc2vec processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use doc2vec\n",
    "# use doc2vec\n",
    "# use doc2vec\n",
    "# use doc2vec\n",
    "\n",
    "# process vector features\n",
    "train_name_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/train_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "train_authors_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/train_authors_doc2vec20.csv\", index_col = False, delimiter = ',', header=None)\n",
    "train_desc_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/train_desc_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "other_features_df = train_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language', 'rating_label'])\n",
    "train_features = pd.concat([train_name_features, train_authors_features, train_desc_features, other_features_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use doc2vec\n",
    "# use doc2vec\n",
    "# use doc2vec\n",
    "# use doc2vec\n",
    "\n",
    "# process test features\n",
    "test_name_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/test_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_authors_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/test_authors_doc2vec20.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_desc_features = pd.read_csv(r\"./project_data_files/book_text_features_doc2vec/test_desc_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "test_other_features_df = test_df.drop(columns=['Name', 'Authors', 'Description', 'Publisher', 'Language'])\n",
    "test_features = pd.concat([test_name_features, test_authors_features, test_desc_features, test_other_features_df], axis=1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutualInformation selection\n",
    "selected_features,selected_features_test = feature_select.MI(train_df,train_features,test_features,12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2\n",
    "selected_features,selected_features_test = feature_select.chi_square(train_df,train_features,test_features,12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save npz\n",
    "save_npz('selected_features.npz', selected_features)\n",
    "save_npz('selected_features_test.npz', selected_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature loading\n",
    "selected_features = load_npz(\"...\")\n",
    "selected_features_test = load_npz(\"...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Decision Tree as clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(selected_features, train_df[\"rating_label\"], test_size=0.2, random_state=66)\n",
    "# bagging \n",
    "base_learner = DecisionTreeClassifier()\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_learner, n_estimators=500, random_state=66)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Random Forest as clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(selected_features, train_df[\"rating_label\"], test_size=0.2, random_state=66)\n",
    "# bagging \n",
    "base_learner = RandomForestClassifier()\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_learner, n_estimators=500, random_state=66)\n",
    "bagging_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modle evalutaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = bagging_clf.score(X_val, y_val)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export prediction\n",
    "y_pred = bagging_clf.predict(selected_features_test)\n",
    "output_df = pd.DataFrame({'rating_label': y_pred})\n",
    "output_df.index += 1\n",
    "output_df.index.name = 'id'\n",
    "output_df.to_csv('./predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
